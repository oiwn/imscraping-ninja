+++
date = "2012-11-27T01:09:41+07:00"
description = "Get structured data from 2 big movies sites"
final_result = "Postgres dump, archive with images"
pages_crawled = 1320000
title = "Two scoops of movies"
+++
Crawled 2 big movie sites:

- imdb.com 900'000 movies, 5.4Gb of images
- kinopoisk.ru 420'000 movies 8.1Gb of images

From each page crawler extracted required movie attributes (actors, genre etc.)
and cover image in `jpg` format.

Another one requirement was to map movies from one site to another. Which was done.
